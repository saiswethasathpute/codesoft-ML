#codesoftML
#task-5
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation
from tensorflow.keras.optimizers import Adam




# For simplicity, let's assume we're using a
text = """hello world this is a simple text generation example using lstm"""


chars = sorted(set(text))
char_to_idx = {char: idx for idx, char in enumerate(chars)}
idx_to_char = {idx: char for idx, char in enumerate(chars)}


encoded_text = [char_to_idx[char] for char in text]


sequence_length = 40  # Length of each input sequence
X = []
y = []

for i in range(len(encoded_text) - sequence_length):
    X.append(encoded_text[i:i + sequence_length])
    y.append(encoded_text[i + sequence_length])

X = np.array(X)
y = np.array(y)


X = np.expand_dims(X, axis=-1)  # (num_samples, sequence_length, 1)
y = tf.keras.utils.to_categorical(y, num_classes=len(chars))  # One-hot encode labels



model = Sequential()
model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(128))
model.add(Dense(len(chars)))
model.add(Activation('softmax'))


model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))


model.fit(X, y, batch_size=128, epochs=50, verbose=1)


def generate_text(model, start_string, num_generate=100):
    
    input_eval = [char_to_idx[char] for char in start_string]
    input_eval = np.expand_dims(input_eval, axis=-1)

    
    generated_text = start_string

    
    for _ in range(num_generate):
        predictions = model.predict(input_eval)
        predicted_id = np.argmax(predictions, axis=-1)[0]

        
        generated_text += idx_to_char[predicted_id]

        
        input_eval = np.expand_dims([predicted_id], axis=-1)

    return generated_text


start_string = "hello"
generated_text = generate_text(model, start_string, num_generate=200)

print("Generated text:\n", generated_text)
